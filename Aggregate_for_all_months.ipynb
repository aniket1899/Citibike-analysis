{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bb9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import sum,avg,max,count, hour, when, col, date_format, month, to_date\n",
    "\n",
    "# from mrjob.job import MRJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f63983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars\n",
    "_DATA_OG_PATH = 'data/original/'\n",
    "_DATA_AGG_PATH = 'data/aggregated/'\n",
    "_YEARS = ['2019', '2020', '2021', '2022']\n",
    "_MONTHS = [str('0' + str(m))[-2:] for m in range(1, 13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cec618",
   "metadata": {},
   "source": [
    "### Move all files to folders sorted by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fee1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files to 'year' folders\n",
    "# import os\n",
    "\n",
    "# years = ['2019', '2020', '2021', '2022']\n",
    "# path = 'data/data_unzipped/'\n",
    "# all_files = os.listdir(path)\n",
    "# files_year = {year:[f for f in all_files if os.path.isfile(os.path.join(path, f)) and year in f] for year in years}\n",
    "\n",
    "# for year in files_year:\n",
    "#     tmp = ' '.join(map(lambda x: os.path.join(path, x), files_year[year]))\n",
    "#     os.system(f'mv {tmp} {os.path.join(path, year)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8975f9",
   "metadata": {},
   "source": [
    "### Transform all files - extract 'month', 'year', 'total_distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5463494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_and_save(year = '2019'):\n",
    "#     assert year in _YEARS\n",
    "#     files = listdir(join(_DATA_PATH, year))\n",
    "#     for path in files:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9ab14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ac7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import month\n",
    "from xml.dom.expatbuilder import FilterVisibilityController\n",
    "\n",
    "\n",
    "def group_and_save(filename: str):\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    spark = SparkSession.builder.master(\"local[*]\").appName('citibike').getOrCreate()\n",
    "    try:\n",
    "        data = spark.read.option(\"header\",True).csv(join(_DATA_OG_PATH, '2019', filename))\n",
    "        print('---')                        \n",
    "        print(f'File name: {FilterVisibilityController]}')\n",
    "        print('---')   \n",
    "    except Exception as e:\n",
    "        print('File read error')\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    stats['count'] = data.count()\n",
    "\n",
    "    data = data.withColumn('month', month(to_date(col('starttime'))))\n",
    "\n",
    "    data = data.withColumn('tripduration', data['tripduration'].cast(IntegerType())) \\\n",
    "                            .withColumn('birth year', data['birth year'].cast(IntegerType())) \\\n",
    "                            .withColumn('gender', data['gender'].cast(IntegerType())) \\\n",
    "                            .withColumn('starttime', data['starttime'].cast(TimestampType())) \\\n",
    "                            .withColumn('stoptime', data['stoptime'].cast(TimestampType())) \n",
    "                            \n",
    "    data = data.withColumn('startTimeHour',hour(col('starttime')))\n",
    "\n",
    "                         \n",
    "    print('Schema')\n",
    "    print(data.printSchema())\n",
    "    print('---')                        \n",
    "\n",
    "\n",
    "    # time of day extract\n",
    "    data = data.withColumn('startTimePeriod',\n",
    "                     when(hour(col('starttime')) < 6, 'midnight')\\\n",
    "                    .when((hour(col('starttime')) >= 6) & (hour(col('starttime')) < 12), 'morning')\\\n",
    "                    .when((hour(col('starttime')) >= 12) & (hour(col('starttime')) < 17), 'afternoon')\\\n",
    "                    .when(hour(col('starttime')) >= 17, 'evening')\n",
    "                    )\n",
    "    # aggregate\n",
    "    try:\n",
    "        groupTrip = data.groupBy(['start station name', 'end station name', 'usertype', 'startTimeHour', 'month']) \\\n",
    "                        .agg(count(\"*\").alias(\"count\"), \\\n",
    "                             sum(\"tripduration\").alias(\"totaltripduration\"))\n",
    "\n",
    "        groupTrip.repartition(1)\\\n",
    "        .write.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(join(_DATA_AGG_PATH, 'TRIPSUMM_' + filename))\n",
    "        print('AGGTRIP File saved')\n",
    "        groupTrip.drop('*')\n",
    "    except Exception as e:\n",
    "        print('AGG TRIP: File save error')\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        groupDemo = data.groupBy(['birth year', 'gender', 'usertype', 'startTimePeriod', 'month']) \\\n",
    "                        .agg(count(\"*\").alias(\"count\"), \\\n",
    "                             sum(\"tripduration\").alias(\"totaltripduration\"))\n",
    "\n",
    "        groupDemo.repartition(1)\\\n",
    "        .write.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save(join(_DATA_AGG_PATH, 'TRIPSUMM_' + filename))\n",
    "        print('AGGDEMO File saved')\n",
    "        groupDemo.drop('*')\n",
    "    except Exception as e:\n",
    "        print('File save error')\n",
    "        print(e)\n",
    "\n",
    "    spark._sc.stop()\n",
    "    print('='*10)\n",
    "\n",
    "    return stats\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6db504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "File name: {files2019[0]}\n",
      "---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "formatmonth() missing 1 required positional argument: 'themonth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6ab31386647f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcounts2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles2019\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcounts2019\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-740f53af78a6>\u001b[0m in \u001b[0;36mgroup_and_save\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starttime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tripduration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tripduration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIntegerType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: formatmonth() missing 1 required positional argument: 'themonth'"
     ]
    }
   ],
   "source": [
    "files2019 = listdir(join(_DATA_OG_PATH, '2019'))\n",
    "counts2019 = {}\n",
    "for filename in files2019:\n",
    "    stats = group_and_save(filename)\n",
    "    if stats:\n",
    "        counts2019[filename] = stats['count']\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdcde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d92d9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|    8|\n",
      "+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('citibike').getOrCreate()\n",
    "try:\n",
    "    data = spark.read.option(\"header\",True).csv(join(_DATA_OG_PATH, '2019', files2019[0]))\n",
    "except Exception as e:\n",
    "    print('File read error')\n",
    "    print(e)\n",
    "\n",
    "data = data.withColumn('month', month(to_date(col('starttime'))))\n",
    "data.select('month').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c584bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
